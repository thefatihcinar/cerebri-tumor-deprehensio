{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Cerebri Tumor Deprehensio\n\na Radically Enhanced Artifical-Intelligence Based Solution for Detecting the Brain Tumor from X-Ray Images of Brain\n\n<img src=\"https://www.drugs.com/health-guide/images/3c7b18a8-c266-455c-b552-dd660d9fac50.jpg\" width=400>","metadata":{}},{"cell_type":"markdown","source":"## Overview of the Contents\n### 1. Aim of the Project\n### 2. What is Brain Tumor\n### 3. Exploration of the Dataset\n### 4. Global Configurations and Functions\n### 5. Import The Necessary Libraries\n### 6. Loading the Dataset\n### 7. The Theory Behind Convolutional Neural Networks\n### 8. Building the Model\n### 9. Training the Model\n### 10. Saving the Model\n### 11. Plotting the Model\n### 12. Model Evaluation\n#### 12.1 Plotting Accuracy\n#### 12.2 Plotting Loss\n### 13. Conclusion\n\n","metadata":{}},{"cell_type":"markdown","source":"# Step 1. Aim of the Project","metadata":{}},{"cell_type":"markdown","source":"__The aim of this project is to train a neural network with thousands of Brain X-ray images of people with Brain Tumor and make computer to learn what Brain Tumor is and how to detect it. The high accuracy, speed and efficiency of the artificial intelligence program can be utilized in the diagnosis of Brain Tumor.__\n<br><br>\n__Because while it may take many years to train and be specialized a doctor, it may take only a few days or even hours to train and specialize an Artificial Intelligence model. Therefore, training and using a deep learning model in the diagnosis of the disease saves a great deal of time.__\n<br><br>\n__Also in recent studies, it has been determined that a trained artificial intelligence model can diagnose diseases accurately in a shorter time and at a higher rate than doctors. This shows that the accuracy of the machines is more reliable.__\n\n<img src=\"https://miro.medium.com/max/1180/1*WCYlOskUZ3dXFbgbXC0ZHg@2x.png\" width=\"450\">","metadata":{}},{"cell_type":"markdown","source":"# Step 2. What is Brain Tumor?","metadata":{}},{"cell_type":"markdown","source":"**A brain tumor is a mass or growth of abnormal cells in your brain.**\n\nMany different types of brain tumors exist. Some brain tumors are noncancerous (benign), and some brain tumors are cancerous (malignant). Brain tumors can begin in your brain (primary brain tumors), or cancer can begin in other parts of your body and spread to your brain as secondary (metastatic) brain tumors.\n\nHow quickly a brain tumor grows can vary greatly. The growth rate as well as the location of a brain tumor determines how it will affect the function of your nervous system.\n\nBrain tumor treatment options depend on the type of brain tumor you have, as well as its size and location.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://static.dw.com/image/36871896_101.jpg\" width=600>","metadata":{}},{"cell_type":"markdown","source":"# Step 3. Exploration of the Dataset\n\n<img src = \"https://thumbs.dreamstime.com/b/film-ray-brain-tumor-my-mom-bangkok-thailand-film-ray-brain-tumor-my-mather-bangkok-thailand-146994631.jpg\" width=700>\n","metadata":{}},{"cell_type":"markdown","source":"This dataset consists of Brain X-Ray Images of Healthy and Tumurous brains. There are 5000 X-Ray Images. The X-Ray Images are categorized inside folders as \"Healthy\" and \"Brain Tumor\". Some Images are RGB, some are mono-color. Additionally, images vary in dimensions sometimes.","metadata":{}},{"cell_type":"markdown","source":"# Step 4. Global Configurations and Functions","metadata":{}},{"cell_type":"markdown","source":"## Configurations\n\nConfigurations are not necessary to utilize, however, it is best practise to control the flow of the neural network from only one source.\nThat is why Cerebri Tumor Deprehensio has a global configuration system.\nA lot of internal stuff about the neural network can be changed only from the configurations panel.\n\n<img src=\"https://www.serverwatch.com/wp-content/uploads/2021/09/SW.ConfigurationManagement-scaled.jpg\" alt=\"configuration-image\" width=\"700\"/>","metadata":{}},{"cell_type":"code","source":"\"\"\"\n    THE CONFIGURATIONS PANEL\n\"\"\"\n\n# These are the configurations that affect the whole kernel. \n# These variables and configurations are used by a lot of functions. \n\nimageSize = 150 # this neural network will work with this image size\nimageSizeAsTuple = (imageSize, imageSize)\nabsoulutePathDataset = \"/kaggle/input/brian-tumor-dataset/Brain Tumor Data Set/Brain Tumor Data Set/\"\n# Had the training done in a local environemnt, this URL would change a little.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:29:23.342744Z","iopub.execute_input":"2022-05-08T04:29:23.343068Z","iopub.status.idle":"2022-05-08T04:29:23.371622Z","shell.execute_reply.started":"2022-05-08T04:29:23.342987Z","shell.execute_reply":"2022-05-08T04:29:23.370987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 5. Importing the Necessary Libraries\n\n\n## The Libraries and Tools Used\n\n<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/2/2d/Tensorflow_logo.svg/1200px-Tensorflow_logo.svg.png\" width=\"70\">\n<img src=\"https://keras.io/img/logo.png\" width=\"140\">\n<img src=\"https://matplotlib.org/3.4.3/_static/logo2_compressed.svg\" width=\"150\">\n\n\n","metadata":{}},{"cell_type":"code","source":"# Tensorflow\nimport tensorflow as tf\n\n# Keras\nfrom tensorflow import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPool2D, LeakyReLU, BatchNormalization, Dropout, Dense, InputLayer, Flatten\nfrom keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.utils.vis_utils import plot_model\nfrom keras import utils, callbacks\nfrom keras.models import Sequential\n\n# Mat Plot Library\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:30:18.458475Z","iopub.execute_input":"2022-05-08T04:30:18.458788Z","iopub.status.idle":"2022-05-08T04:30:24.864383Z","shell.execute_reply.started":"2022-05-08T04:30:18.458756Z","shell.execute_reply":"2022-05-08T04:30:24.863308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 6. Loading the Dataset","metadata":{}},{"cell_type":"markdown","source":"![loading-dataset](https://us.123rf.com/450wm/transylvania/transylvania1811/transylvania181105279/112397982-network-database-flat-white-icons-on-round-color-backgrounds-17-background-color-variations-are-incl.jpg?ver=6)","metadata":{}},{"cell_type":"markdown","source":"The images are structured in a containing folder. There must be imported, in other words, loaded into the memory. Keras' ImageDataGenerator class provides a method called \"flow from directory\", namely, that allows researchers to load images from a specific directory __with their labels__. It's important.","metadata":{}},{"cell_type":"code","source":"\n# Determining the Train-Validation Split Ration\n## Generally at least 15 percent is recommended for neural network to learn greatly.\ntrainValidationSplitRatio = 22 / 100\nnormalizationFactor = 1.0 / 255\nzoomRange = ( 1-0.01, 1-0.01 )\n\n\n\n# ImageDataGenerator generates a tf.data.Dataset from image files in a directory\ngenerator = ImageDataGenerator(\n    rescale= normalizationFactor,\n    validation_split = trainValidationSplitRatio,\n    dtype = tf.float32, \n    zoom_range = zoomRange )\n\n\n# Rescaling value is provided as 1 / 255 in other words, each pixel is normalized by being divided to 255.\n\n# Data type is chosen as Floating data type.\n# Zoom Range is assigned, it means data is augmented by making random zooms in this range.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:30:30.240118Z","iopub.execute_input":"2022-05-08T04:30:30.240381Z","iopub.status.idle":"2022-05-08T04:30:30.246112Z","shell.execute_reply.started":"2022-05-08T04:30:30.240354Z","shell.execute_reply":"2022-05-08T04:30:30.245007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bear in mind that, by providing a split ratio to the generator, train-validation split is handled.****","metadata":{}},{"cell_type":"markdown","source":"**Also keep in mind that, NORMALIZATION IS DONE IN THIS STEP AS WELL.**","metadata":{}},{"cell_type":"markdown","source":"Another point, **Data Augmentation** to some degree is done in this step as well, by providing **zoom range** for example.","metadata":{}},{"cell_type":"markdown","source":"The ImageDataGenerator class has three methods flow(), flow_from_directory() and flow_from_dataframe() to read the images from a big numpy array and folders containing images.\n\nThe directory must be set to the path where your ‘n’ classes of folders are present. <br/>\nThe target_size is the size of your input images, every image will be resized to this size.<br/>\n**color_mode**: if the image is either black and white or grayscale set “grayscale” or if the image has three color channels, set “rgb”.<br/>\n**batch_size**: No. of images to be yielded from the generator per batch.<br/>\n**class_mode**: Set “binary” if you have only two classes to predict, if not set to“categorical”, in case if you’re developing an Autoencoder system, both input and the output would probably be the same image, for this case set to “input”.<br/>\n**shuffle**: Set True if you want to shuffle the order of the image that is being yielded, else set False.<br/>\n**seed**: Random seed for applying random image augmentation and shuffling the order of the image.<br/>","metadata":{}},{"cell_type":"code","source":"batchCoefficientTraining = 128\nbatchCoefficientValidation = 4\n# batch_size states number of images to be yielded from the generator per batch.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:30:33.872781Z","iopub.execute_input":"2022-05-08T04:30:33.87311Z","iopub.status.idle":"2022-05-08T04:30:33.878158Z","shell.execute_reply.started":"2022-05-08T04:30:33.873073Z","shell.execute_reply":"2022-05-08T04:30:33.876824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"randomSeed = 1997","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:30:34.747453Z","iopub.execute_input":"2022-05-08T04:30:34.747737Z","iopub.status.idle":"2022-05-08T04:30:34.752051Z","shell.execute_reply.started":"2022-05-08T04:30:34.747701Z","shell.execute_reply":"2022-05-08T04:30:34.751191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"RGB_COLORS = \"rgb\"\n# RGB Color Format found out to be better choice in this project. Because it has simply more data in it.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:30:35.268036Z","iopub.execute_input":"2022-05-08T04:30:35.268304Z","iopub.status.idle":"2022-05-08T04:30:35.272773Z","shell.execute_reply.started":"2022-05-08T04:30:35.268276Z","shell.execute_reply":"2022-05-08T04:30:35.271601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the training data from the given location.\n\ntrain = generator.flow_from_directory(absoulutePathDataset,\n                               target_size = imageSizeAsTuple,\n                               subset = \"training\", # generate the training data from these folders\n                               batch_size = batchCoefficientTraining,\n                               class_mode = \"binary\",\n                               color_mode = RGB_COLORS,\n                               shuffle = True,\n                               seed = randomSeed)\n\n\n# Here is the training data.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:00.84337Z","iopub.execute_input":"2022-05-08T04:31:00.843659Z","iopub.status.idle":"2022-05-08T04:31:04.690562Z","shell.execute_reply.started":"2022-05-08T04:31:00.843627Z","shell.execute_reply":"2022-05-08T04:31:04.689915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation = generator.flow_from_directory(absoulutePathDataset,\n                               target_size = imageSizeAsTuple,\n                               subset = \"validation\",  # generate the validation data from these folders\n                               batch_size = batchCoefficientValidation,\n                               class_mode = \"binary\", # binary classification is done\n                               color_mode = RGB_COLORS,\n                               shuffle = True,\n                               seed = randomSeed)\n# Here is the validation data.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:07.16808Z","iopub.execute_input":"2022-05-08T04:31:07.168617Z","iopub.status.idle":"2022-05-08T04:31:07.819912Z","shell.execute_reply.started":"2022-05-08T04:31:07.168584Z","shell.execute_reply":"2022-05-08T04:31:07.818953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 7. The Theory of Convolutional Neural Networks","metadata":{}},{"cell_type":"markdown","source":"Convolutional neural networks are used for image classification mainly.\nTypically, convolutional neural networks are super similar to the artifical neural networks. \nThe only difference is the fact that CNNs work with images mainly, that is why they preprocess images (in convolution layers) \nbefore sending processed pixels to the ANN.\n\n<br>\n\n## Architecture of Convolutional Neural Networks (CNN)\n\n<br>\n\n<img src=\"https://miro.medium.com/max/2510/1*vkQ0hXDaQv57sALXAJquxA.jpeg\" width=\"950\">\n\n<br>\n\nIn the figure above, an overview of a CNN is seen. It is just a representation of CNNs, does not reflect the neural network we've developed here.\n\n### What is an Image?\n\nInputs to CNNs are IMAGES. Images are numbers, in other words, array of pixels. <br>\nIn simple terms, IMAGES ARE MATRICES. <br>\n\nEach pixel has an RGB value between 0-255. <br>\n \n<img src=\"https://previews.123rf.com/images/papulov74/papulov741802/papulov74180200002/96082800-extremely-closed-shot-of-lcd-tv-rgb-pixel.jpg\" width=\"700\">\n\n### Test and Train Split\n\n<img src = \"https://miro.medium.com/max/1400/1*-8_kogvwmL1H6ooN1A1tsQ.png\" width=\"650\">\n\n__In not just Convolutional Neural networks but also Artificial Neural networks as well, a split method is observed. It is generally known as TEST-TRAIN SPLIT.__\n\n__It refers to splitting the overall dataset into two parts, not equally, generally in a way that test part is not more than 15% of the entire dataset, in order to be able to TEST THE ACCURACY, EFFICIENT, LOSS OF THE NEURAL NETWORK.__\n\n__Consider the scenerio where a split is not performed and the neural network is fed with all the dataset, in this case, it would be IMPOSSIBLE TO TEST THE NEURAL NETWORK.__\n\n_To sum up, Test-Train split is performed, to split the data into two parts, and it avoids overfitting._\n\n\n## Normalization\n\n<img src=\"https://miro.medium.com/max/1083/1*onZIiGguLfbUYs3aTtmijg.jpeg\" width=\"500\">\n\nIn a typical neural network, trillions of mathematicals operations are done. \n\nFrom derivatives to multiplications. \n\nIf we use values between 0-255, it would slow the neural network down. So it is best to rearrange the values between 0-1. \n\nThis is called NORMALIZATION.\n\n\n## Reshape\n\n<img src=\"https://deeplearningtricks.files.wordpress.com/2021/11/proper-reshape-1.jpg?w=768\" width=\"600\">\n\nThe same logic as normalization. An image might have more than one million pixels. \n\nConsider example 1920 x 1080. It means 2 million pixels. \n\nThe NN can’t be trained with this much of pixel values. \n\nTherefore, we lose some pixel information, we lose some details of the image by reshaping it.\n\n## Label Encoding\n\n<img src=\"https://www.mertmekatronik.com/uploads/images/2020/10/image_750x_5f8c7d06319f9.jpg\" width=\"400\">\n\nLabels are strings. But computers work with numbers. Therefore we convert STRING LABELS TO NUMBERS.\n\nKeras does this in a similar manner like BYTE-ARRAY.\n\nFor label 2, it uses [0,0,1,0,0,0,0,0]\n\n## Patterns and Pattern Recognition\n\nObjects in real life, consist of small parts, such as circles, points, lines, edges. \n\nConsider a square, for example, it consists of 4 different lines.\n\nConsider an eye, for example, it consists of tons of circles and very small lines.\n\nIf, HOWEVER, we could ever figure out a way TO DISTINGUISH THOSE SMALL PARTS, WE WOULD BE ABLE TO DISTINGUISH BIGGER OBJECTS as well.\n\n\n## Convolutions and Convolution Operation\n\nConvolution Operation is basically FEATURE DETECTORS.\n\nWe apply convolution kernels(matrices) to the image. It can be a 3x3 matris for example.\n\nBy applying these kind of matrices, we are able to detect basic primitive structures.\n\nIn other words, THIS IS FEATURE DETECTING.\n\n![CONVOLUTION-OPERATION](https://miro.medium.com/max/1400/1*ROh_38pysewuh6fVPQpxFQ.png)\n\n### Feature detector detects features, like edges or convex shapes. \n\n\n## Applying Activation Function ReLU During Convolution Operation\n\nApply an activation function, better apply ReLU(Rectified Linear Units), to break up linearity.\n\n![relu](https://miro.medium.com/max/1400/1*XxxiA0jJvPrHEJHD4z893g.png)\n\nAs seen negative values are gone after ReLU. Linearity is broken.\n\nNon-linearity is DESIRED in AI. Because if linearity continues, all the operations would be affected by each other and there would be no mean to apply tons of operations.\n\nBy appling ReLU, linearity is broken. \n\n\n## Padding\n\nAfter applying convolution operation, the size of the image IS REDUCED.\n\nThis is not something desired during convolution operation. \n\nTherefore, we apply PADDING to the image,\n\ni.e. Size of the image is first INCREASED, and then by convolution operation it is reduced TO THE SAME SIZE AS BEFORE.\n\nThat is why called SAME PADDING.\n\nBy appling same padding, LOSS OF INFORMATION IS AVOIDED.\n\n![padding](http://xrds.acm.org/blog/wp-content/uploads/2016/06/Figure_3.png)\n\n\n## Pooling\n\nWe can’t keep all the information in the image till the artificial neural network. That would make a vector of hundreds of thousands of pixel information and that would make it impossible to train the ANN.\n\nThat is why we need to choose representatives. This means we divide the image into pools, and choose a value to represent that pool,\nin the end, even though some pixel information is lost, this would make it real to train the ANN.\n\nThis is called DOWN-SAMPLING.\n\nTechniques such as Max Pooling, Average Pooling etc. can be applied.\n\n<img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png\"  width=\"700\">\n\n\n## Flattening\n\nArtifical Neural Networks work with vectors, that is why we need to FLATTEN, \n\nin other words, convert the 2D, 3D matrix into 1D Vector. \n\nAnd then we can feed it to ANN.\n\n![flattening](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/73_blog_image_1.png)\n\n\n## Full Connection Layer (Artifical Neural Network)\n\nAfter processing the image with convolution operations and pooling operations, we have a vector that represent our image, 1D vector,\n\nthis will get into an Artifical Neural Network, to make predictions.\n\n\n**Input Layer**: Input is 1D vector, that represents our image.\n\n**Hidden Layers**: Similar to the nature of human brains, that is extremely complex and made up of convolutions and layers. \nThe more hidden layers, the better the Neural Network.\n\n**Output Layer**: The prediction, made by the Neural Network\n\n![full-connection](https://sds-platform-private.s3-us-east-2.amazonaws.com/uploads/74_blog_image_1.png)\n\n\nIn this operation, all the neurons above are connected to each other. And all the Convolutional Neural Network is done.\n\n## Applying Dropout\n\nDropout is a technique to break connections between some neurons that are randomly selected.\n\nThe aim is to make the Artifical Neural Network (ANN) more stable and to avoid memorizing the data. \n\nMathematical counterpart is ignoring some neurons while making a forward-propagation.\n\n![dropout](https://3.bp.blogspot.com/-W4llqbhI44U/VjUuHTUVFmI/AAAAAAAABxA/gyyuO9CA-tsGdrqpLXNMoqMoIAT45l2MACPcBGAYYCw/s1600/Droput.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Step 8. Building the Model","metadata":{}},{"cell_type":"code","source":"# This is the actual brain of the this project, hence the most important part.\n\ndef buildTheModel(inputShape):\n    # this function builds the convolutional neural network for that can later be trained accordingly\n    \n    ## -- CONFIGURATIONS PANEL OF THE NEURAL NETWORK --\n    # Configurations for this convolutional neural network, if need be, configurations can be changed directly from this panel\n    ACTIVATION =  \"relu\"\n    PADDING = \"same\"\n    SIGMOID = \"sigmoid\"\n    LOSS = \"binary_crossentropy\"\n    ACCURACY = \"accuracy\"\n    \n    model = Sequential() # Create a CNN model\n    \n    # -- CONVOLUTION LAYERS --  (Feature Detectors)\n        \n    ## Convolution Layer 1\n    model.add(InputLayer( input_shape = inputShape ))\n    model.add(Conv2D(filters = 32, # Number of filters\n                     kernel_size = 3, # Dimension of Filter Matrix, specifying the height and width of the 2D convolution window\n                     padding = PADDING, # Padding operation\n                     activation = ACTIVATION)) # Break up linearlity after filtering\n    \n    model.add(Dropout(0.10))\n    \n    # Batch normalization applies a transformation that maintains the mean output close to 0 and the output standard deviation close to 1.\n    model.add(BatchNormalization( axis = -1,\n                                 momentum = 0.99,\n                                 epsilon = 0.001,\n                                 center = True,\n                                 scale = True,\n                                 beta_initializer = \"zeros\",\n                                 gamma_initializer = \"ones\",\n                                 moving_mean_initializer = \"zeros\",\n                                 moving_variance_initializer = \"ones\",\n                                 beta_regularizer = None,\n                                 gamma_regularizer = None,\n                                 beta_constraint = None,\n                                 gamma_constraint = None))\n    \n    \n    # Max pooling is the best pooling technique to apply. Get the maximum of the matrix.\n    model.add( MaxPool2D( pool_size = (2, 2),\n                         strides = None,\n                         padding = 'valid'))\n    \n    \n    ## Convolution Layer 2\n    model.add(Conv2D(filters = 64, # Number of filters\n                     kernel_size = 3, # Dimension of Filter Matrix\n                     padding = PADDING, # Padding operation\n                     activation = ACTIVATION)) # Break up linearlity after filtering  \n    \n    model.add(Dropout(0.15))\n    \n    model.add(BatchNormalization( axis = -1,\n                                 momentum = 0.99,\n                                 epsilon = 0.001,\n                                 center = True,\n                                 scale = True,\n                                 beta_initializer = \"zeros\",\n                                 gamma_initializer = \"ones\",\n                                 moving_mean_initializer = \"zeros\",\n                                 moving_variance_initializer = \"ones\",\n                                 beta_regularizer = None,\n                                 gamma_regularizer = None,\n                                 beta_constraint = None,\n                                 gamma_constraint = None))\n\n    model.add( MaxPool2D( pool_size = (2, 2),\n                         strides = None,\n                         padding='valid'))\n    \n    \n    ## Convolution Layer 3\n    model.add(Conv2D(filters = 32, # Number of filters\n                     kernel_size = 3, # Dimension of Filter Matrix\n                     padding = PADDING, # Padding operation\n                     activation = ACTIVATION)) # Break up linearlity after filtering     \n    \n    model.add( MaxPool2D( pool_size = (2, 2),\n                         strides = None,\n                         padding='valid'))\n    \n    \n    model.add(Flatten())\n\n    # THE HIDDEN LAYER\n    model.add(Dense(units = 156, # 156 Neurons as input\n                    activation = ACTIVATION)) # ReLU is for breaking linearity.\n    model.add(BatchNormalization())\n    model.add(Dropout(0.25)) # the last dropout\n    \n    model.add(Dense(64, activation = ACTIVATION))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.35)) \n    \n    model.add(Dense(units = 1 , activation = SIGMOID))\n    # At the end of the neural network, sigmoid is chosen as an activation function \n    # becuase only two different kinds of output exist. Brain Tumor or Healthy.\n    \n    # Compilation of the Model\n    model.compile(optimizer = Adam( learning_rate = 0.002, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-07, amsgrad = False), \n                  loss = BinaryCrossentropy(), \n                  metrics = [ACCURACY])\n    \n    print(\"Model is successfully created.\")\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:14.153455Z","iopub.execute_input":"2022-05-08T04:31:14.154061Z","iopub.status.idle":"2022-05-08T04:31:14.168939Z","shell.execute_reply.started":"2022-05-08T04:31:14.154009Z","shell.execute_reply":"2022-05-08T04:31:14.167752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Learning Rate Optimizer**\n\n**While doing back propagation, learning reate is one of the most critical factors while learning, (i.e. taking derivative of the cost function), if learning rate is high, the neural network might not be able to learn, if it is too low, it might not learn at all.**\n\nIn this project, Adam Optimizer is chosen to be used. \nAdam optimization is a stochastic gradient descent method that is based on adaptive estimation of first-order and second-order moments.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://machinelearningmastery.com/wp-content/uploads/2017/05/Comparison-of-Adam-to-Other-Optimization-Algorithms-Training-a-Multilayer-Perceptron.png\">","metadata":{}},{"cell_type":"code","source":"# Compute the Input Shape\nnumberofColorChannels = 3\n# number of color channels is 3 because this neural networks works with RGB colors\ninputShape = (imageSize, imageSize, numberofColorChannels)\n\n\nmodel = buildTheModel(inputShape) # Compile and Build the model accodingly","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:21.673792Z","iopub.execute_input":"2022-05-08T04:31:21.674095Z","iopub.status.idle":"2022-05-08T04:31:21.931925Z","shell.execute_reply.started":"2022-05-08T04:31:21.67406Z","shell.execute_reply":"2022-05-08T04:31:21.931071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary of the Model","metadata":{}},{"cell_type":"code","source":"model.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:25.910267Z","iopub.execute_input":"2022-05-08T04:31:25.91106Z","iopub.status.idle":"2022-05-08T04:31:25.924625Z","shell.execute_reply.started":"2022-05-08T04:31:25.911003Z","shell.execute_reply":"2022-05-08T04:31:25.92397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 9. Training the Model","metadata":{}},{"cell_type":"markdown","source":"All the steps until now are all about configurations about the neural network, now is the time for training the neural network.\n\n__After this step, it is expected that the neural network succesfully learns the weights and biases that are highyl accurate.__","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://ml4a.github.io/images/figures/connection_tweak.png\" width=\"500\">","metadata":{}},{"cell_type":"markdown","source":"##### Some key concepts about the training process:\n\n### Epochs\n__the number of complete passes through the training dataset__\n\n### Batch Size\n__a number of samples processed before the model is updated__","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/1010/1*AOiD8LEDWrWy5l_f9qgweQ@2x.jpeg\" width=\"450\">","metadata":{}},{"cell_type":"code","source":"# fit() method on model of Keras Library actually trains the neural networks.\n\n# Configurations About Training\n\nBATCH_SIZE = 16\nEPOCHS = 12 # the optimal value is 20 - 24.","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:29.740379Z","iopub.execute_input":"2022-05-08T04:31:29.740634Z","iopub.status.idle":"2022-05-08T04:31:29.744719Z","shell.execute_reply.started":"2022-05-08T04:31:29.740606Z","shell.execute_reply":"2022-05-08T04:31:29.743931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Early Stopping\n\nAn **Early Stopping Mechanism** better be set up. \nWhat Early Stopping Basically does is **stop training when a monitored metric has stopped improving.**\n\n<img src=\"https://miro.medium.com/max/973/1*nhmPdWSGh3ziatQKOmVq0Q.png\" width=\"700\">","metadata":{}},{"cell_type":"code","source":"MONITOR = \"val_loss\" # be monitoring validation loss, when it is beyond the level not suitable, terminate\n# The goal of a training is to minimize the loss.\n\nMODE = \"min\" # minimize the monitoring value\n\nPATIENCE_THRESHOULD = 4 \n# patience: Number of epochs with no improvement after which training will be stopped.\n\nearlyStopping = callbacks.EarlyStopping( monitor = MONITOR, \n                                        mode = MODE, \n                                        patience = PATIENCE_THRESHOULD, \n                                        restore_best_weights = True,\n                                        baseline = None)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:32.773004Z","iopub.execute_input":"2022-05-08T04:31:32.773299Z","iopub.status.idle":"2022-05-08T04:31:32.778681Z","shell.execute_reply.started":"2022-05-08T04:31:32.773264Z","shell.execute_reply":"2022-05-08T04:31:32.777767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit( train, \n                    verbose = 1, \n                    callbacks = [earlyStopping], \n                    epochs = EPOCHS, \n                    validation_data = (validation) )\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:31:35.146795Z","iopub.execute_input":"2022-05-08T04:31:35.147467Z","iopub.status.idle":"2022-05-08T04:49:36.129753Z","shell.execute_reply.started":"2022-05-08T04:31:35.147423Z","shell.execute_reply":"2022-05-08T04:49:36.128917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 10. Saving the Model\n\nNeural networks are generally designed to be served as Software as a Service or Artifical Intelligence as a Service,\nwith this purpose, the __trained neural network, in other words weights and biases__ MUST BE SAVED SOMEWHERE.\n\nThat's where Saving the model practises come in.\n\n__Models are saved as .h5 file.__\n\n<br>\n\n<img src = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQaVyBUJ1_lBDzaCDK1oI-Zqr8CzeX6hNzyHQ&usqp=CAU\" width=\"100\">","metadata":{}},{"cell_type":"code","source":"def savetheModel(model):\n    # this function will save the model locally\n    model.save(\"brain-tumor-detection-model.h5\")\n\n    \nsavetheModel(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:18:00.896747Z","iopub.execute_input":"2022-05-08T04:18:00.89724Z","iopub.status.idle":"2022-05-08T04:18:51.691066Z","shell.execute_reply.started":"2022-05-08T04:18:00.897186Z","shell.execute_reply":"2022-05-08T04:18:51.690216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 11. Plotting the Model","metadata":{}},{"cell_type":"markdown","source":"In this step, the built Convolutional Neural Network Model will be plotted by Keras' Plot Model utility. ","metadata":{}},{"cell_type":"code","source":"plot_model( model, \n           to_file = 'brain-tumor-detection-neural-net.png', \n           show_shapes = True, \n           show_layer_names = True,\n           rankdir = \"TB\",\n           expand_nested = False,\n           dpi = 96,\n           layer_range = None)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:57:30.956004Z","iopub.execute_input":"2022-05-08T05:57:30.956888Z","iopub.status.idle":"2022-05-08T05:57:32.179526Z","shell.execute_reply.started":"2022-05-08T05:57:30.956818Z","shell.execute_reply":"2022-05-08T05:57:32.176402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step 12. Model Evaluation","metadata":{}},{"cell_type":"markdown","source":"Model evaluation is the process of using different evaluation metrics to understand a machine learning model's performance, as well as its strengths and weaknesses. Model evaluation is important to assess the efficacy of a model during initial research phases, and it also plays a role in model monitoring.","metadata":{}},{"cell_type":"markdown","source":"In this project, **validation data** is used as test data. Therefore, we know the model's accuracy.","metadata":{}},{"cell_type":"markdown","source":"## Step 12.1 Plotting Accuracy\n","metadata":{}},{"cell_type":"code","source":"# Draw the Model's Accuracy Graph with respect to epoch \n\nplt.plot( history.history['accuracy'], label = 'accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim( [0, 1] )\nplt.legend(loc='lower right')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T05:57:13.822299Z","iopub.execute_input":"2022-05-08T05:57:13.822585Z","iopub.status.idle":"2022-05-08T05:57:14.056413Z","shell.execute_reply.started":"2022-05-08T05:57:13.822557Z","shell.execute_reply":"2022-05-08T05:57:14.055517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Step 12.2 Plotting Loss","metadata":{}},{"cell_type":"code","source":"# Draw the Model's Loss Graph with respect to epoch \n\nplt.plot( history.history['loss'], label='loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.ylim( [0, 1] )\nplt.legend( loc = 'lower right' ) ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T04:20:17.982303Z","iopub.execute_input":"2022-05-08T04:20:17.982653Z","iopub.status.idle":"2022-05-08T04:20:18.218658Z","shell.execute_reply.started":"2022-05-08T04:20:17.982614Z","shell.execute_reply":"2022-05-08T04:20:18.218009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As clearly seen in the graph, the loss is minimized.","metadata":{}},{"cell_type":"markdown","source":"# Step 13. Conclusion","metadata":{}},{"cell_type":"markdown","source":"__In conclusion, it is extremely essential to build up intelligent systems for a variety of purposes. In this case, a neural network for healthcare issues has been developed.__\n\n<br>\n\n__Most imporantly, Let's focus on why it is crucial to build those intelligence systems. Doctors are humans, and they are prone to errors. In other industries errors are at worst a loss of money, but in healthcare, a mistake might result in death. That is the main reason, we, humans, must develop these intelligent healthcare systems.__\n\n<br>\nThis project is actually a PROOF-OF-CONCEPT. It means that it reflects parts in the future.\n\n__Finally, let's not forget, deep learning is the solution.__","metadata":{}}]}